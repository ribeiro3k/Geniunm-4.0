
import { GoogleGenAI, Chat, GenerateContentResponse, GenerateContentParameters, Part } from "@google/genai";
import { FlashcardContent, Scenario, GeminiMessage, AudioTranscriptionResponse, SimulatorBehavioralProfile } from '../types';
import { GEMINI_SIMULATOR_PROMPT_TEMPLATE, API_KEY_ERROR_MESSAGE, GEMINI_OBJECTION_EVALUATOR_PROMPT, GEMINI_PROCEDURAL_SCENARIO_GENERATION_PROMPT, CUSTOM_SIMULATOR_PROMPT_KEY } from '../constants';

// Acessar a API Key usando process.env.API_KEY
const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  console.error(API_KEY_ERROR_MESSAGE); 
}

const ai = new GoogleGenAI({ apiKey: API_KEY || "MISSING_API_KEY" }); // Passa a chave aqui

export async function generateFlashcardFromGemini(theme: string): Promise<FlashcardContent | null> {
  if (!API_KEY) throw new Error(API_KEY_ERROR_MESSAGE);
  try {
    const model = 'gemini-2.5-flash-preview-04-17';
    const prompt = `
      Crie um flashcard did√°tico, direto ao ponto e com emojis para explicar o conceito de "${theme}", voltado para consultores que vendem cursos EAD da Cruzeiro do Sul Virtual por WhatsApp (gradua√ß√£o e p√≥s).

      O flashcard deve ter:
      üîπ Uma FRENTE contendo um T√çTULO CURTO, DE ALTO IMPACTO E PERSUASIVO (M√ÅXIMO 5-7 PALAVRAS) OU UMA PERGUNTA R√ÅPIDA E PROVOCATIVA sobre o tema '${theme}'. Deve ser extremamente direto, usar linguagem de vendas/marketing eficaz e gerar curiosidade imediata, focado no contexto de vendas da Cruzeiro do Sul Virtual. Exemplos para outros temas: 'Escassez: Venda Mais!', 'Urg√™ncia: Feche Agora!', 'Pre√ßo Alto? Resolvido!', 'WhatsApp que Converte!'. Evite perguntas vagas ou t√≠tulos gen√©ricos. Formato: Texto simples, sem markdown.
      üîπ Um VERSO com:

      üéØ **${theme}: O que √©?**
      üí¨ [Explica√ß√£o r√°pida e clara com emoji (1-2 frases), focada no benef√≠cio para o cliente ou na t√©cnica de venda]

      üí° **Por que funciona?**
      üí¨ [Justificativa concisa (1-2 frases), apelando para psicologia de vendas ou l√≥gica do cliente]

      üéì **Como aplicar na venda EAD (Cruzeiro do Sul Virtual):**
      ‚úÖ [Exemplo pr√°tico 1 com emoji, espec√≠fico para o cen√°rio de venda de cursos EAD da Cruzeiro do Sul]
      ‚úÖ [Exemplo pr√°tico 2 com emoji, espec√≠fico e acion√°vel]
      ‚úÖ [Exemplo pr√°tico 3 com emoji, opcional, mas √∫til se agregar valor diferenciado]

      üí¨ **Frase de Impacto para WhatsApp (Cruzeiro do Sul Virtual):**
      ‚Äú[Exemplo de frase curta, direta, com gatilho mental, que o consultor pode adaptar e usar, incluindo um call-to-action sutil e emojis relevantes. Deve ser espec√≠fico para o contexto da Cruzeiro do Sul Virtual.]‚Äù

      Use uma linguagem leve, informal, mas profissional e f√°cil de ler no celular.
      Foque em ajudar o consultor a ENTENDER o conceito e APLICAR a t√©cnica imediatamente.
      Formate a resposta do verso usando markdown simples (negrito com **, listas com ‚úÖ ou outro emoji apropriado).
      Separe a frente e o verso EXATAMENTE com a string "--VERSO--". NADA MAIS, NADA MENOS.
      Responda apenas com o conte√∫do do flashcard, sem introdu√ß√µes ou despedidas.
    `;

    const response: GenerateContentResponse = await ai.models.generateContent({
        model: model,
        contents: [{ role: "user", parts: [{text: prompt}] }],
        config: { thinkingConfig: { thinkingBudget: 0 } }
    });

    const text = response.text;
    const parts = text.split('--VERSO--');
    const safeThemeIdPart = theme.replace(/\s+/g, '_').replace(/[^a-zA-Z0-9_]/g, '');


    if (parts.length === 2) {
      return { id: `flashcard_theme_${safeThemeIdPart}_${crypto.randomUUID().substring(0,4)}`, front: parts[0].trim(), back: parts[1].trim(), theme };
    } else {
      console.error('Resposta da API Gemini n√£o est√° no formato esperado (frente--VERSO--verso):', text);
      return {
        id: `flashcard_error_format_${safeThemeIdPart}`,
        front: `Erro de Formato: ${theme}`,
        back: `A IA n√£o retornou o card no formato esperado. Resposta recebida:\n\n${text}`,
        theme,
      };
    }
  } catch (error) {
    console.error('Erro ao gerar flashcard com Gemini:', error);
    const safeThemeIdPart = theme.replace(/\s+/g, '_').replace(/[^a-zA-Z0-9_]/g, '');
     return {
        id: `flashcard_error_api_${safeThemeIdPart}`,
        front: `Erro API: ${theme}`,
        back: `Houve um erro ao contatar a IA. Detalhes: ${(error as Error).message}`,
        theme,
      };
  }
}


export async function startChatSession(
  scenario: Scenario, 
  displayInitialAiMessageInChatUI: boolean
): Promise<{chat: Chat; initialAiMessage: string}> {
  if (!API_KEY) throw new Error(API_KEY_ERROR_MESSAGE);

  const customPrompt = localStorage.getItem(CUSTOM_SIMULATOR_PROMPT_KEY);
  let systemInstruction = customPrompt || GEMINI_SIMULATOR_PROMPT_TEMPLATE;

  systemInstruction = systemInstruction.replace(/{SCENARIO_TITLE}/g, scenario.title || "Indefinido");
  systemInstruction = systemInstruction.replace(/{SCENARIO_CONTEXT}/g, scenario.context || "Contexto geral de um aluno interessado em EAD.");
  systemInstruction = systemInstruction.replace(/{SCENARIO_INITIAL_MESSAGE_CONTEXT}/g, scenario.initialMessage || "Interesse geral em cursos EAD.");
  systemInstruction = systemInstruction.replace(/{BEHAVIORAL_PROFILE}/g, scenario.behavioralProfile || "Padr√£o");
  
  const initialHistory: GeminiMessage[] = [];
  if (displayInitialAiMessageInChatUI && scenario.initialMessage) {
    initialHistory.push({ role: 'model', parts: [{ text: scenario.initialMessage }] });
  }

  const currentChat = ai.chats.create({
    model: 'gemini-2.5-flash-preview-04-17',
    config: {
      systemInstruction: systemInstruction,
    },
    history: initialHistory.length > 0 ? initialHistory : undefined
  });
  
  const firstAiMessage = displayInitialAiMessageInChatUI ? scenario.initialMessage : "";


  return { chat: currentChat, initialAiMessage: firstAiMessage };
}


export async function sendChatMessage(chat: Chat | null, userMessageText: string): Promise<string> {
  if (!API_KEY) throw new Error(API_KEY_ERROR_MESSAGE);
  if (!chat) throw new Error("Chat n√£o iniciado.");

  try {
    const response: GenerateContentResponse = await chat.sendMessage({ message: userMessageText });
    return response.text;
  } catch (error) {
    console.error('Erro ao enviar mensagem para Gemini Chat:', error);
    if ((error as any)?.response?.promptFeedback?.blockReason) {
        return `Sua mensagem foi bloqueada pela IA. Motivo: ${(error as any).response.promptFeedback.blockReason}. Por favor, reformule sua mensagem.`;
    }
    return "Desculpe, ocorreu um erro ao processar sua mensagem. Tente novamente.";
  }
}

export async function generateProceduralLeadScenarioFromGemini(): Promise<Scenario | null> {
  if (!API_KEY) throw new Error(API_KEY_ERROR_MESSAGE);
  try {
    const model = 'gemini-2.5-flash-preview-04-17';
    const response: GenerateContentResponse = await ai.models.generateContent({
      model: model,
      contents: [{ role: "user", parts: [{ text: GEMINI_PROCEDURAL_SCENARIO_GENERATION_PROMPT }] }],
      config: { temperature: 0.85, topP: 0.95, thinkingConfig: { thinkingBudget: 0 } } 
    });

    const text = response.text;
    const lines = text.split('\n').map(line => line.trim()).filter(line => line);
    const parsedFields: Record<string, string> = {};

    lines.forEach(line => {
      const separatorIndex = line.indexOf(':');
      if (separatorIndex > -1) {
        const key = line.substring(0, separatorIndex).trim();
        const value = line.substring(separatorIndex + 1).trim();
        parsedFields[key] = value;
      }
    });
    
    const requiredFields = [
        "LEAD_NAME", "LEAD_AGE_APPROX", "LEAD_CURRENT_SITUATION", 
        "COURSE_OF_INTEREST", "LEAD_PRIMARY_MOTIVATION", "LEAD_KEY_CONCERN_OR_DOUBT",
        "LEAD_SUBTLE_PAIN_POINT", "LEAD_SOURCE_HINT", "INITIAL_MESSAGE_TO_CONSULTANT",
        "BEHAVIORAL_PROFILE"
    ];

    for (const field of requiredFields) {
        if (!parsedFields[field]) {
            console.error(`Campo obrigat√≥rio ausente na resposta da IA para cen√°rio procedural: ${field}. Resposta completa:`, text);
            throw new Error(`Formato de cen√°rio procedural inv√°lido: campo ${field} ausente.`);
        }
    }
    
    const title = `${parsedFields.LEAD_NAME} (${parsedFields.COURSE_OF_INTEREST})`;
    const contextParts = [
        `Nome: ${parsedFields.LEAD_NAME}, ${parsedFields.LEAD_AGE_APPROX} anos.`,
        `Situa√ß√£o: ${parsedFields.LEAD_CURRENT_SITUATION}.`,
        `Curso de Interesse: ${parsedFields.COURSE_OF_INTEREST}.`,
        `Principal Motiva√ß√£o: ${parsedFields.LEAD_PRIMARY_MOTIVATION}.`,
        `Principal Preocupa√ß√£o/D√∫vida: ${parsedFields.LEAD_KEY_CONCERN_OR_DOUBT}.`,
        `Ponto de Dor Sutil/Desejo: ${parsedFields.LEAD_SUBTLE_PAIN_POINT}.`,
        `Como chegou at√© n√≥s (pista): ${parsedFields.LEAD_SOURCE_HINT}.`
    ];
    const context = contextParts.join('\n');

    let behavioralProfile = parsedFields.BEHAVIORAL_PROFILE as SimulatorBehavioralProfile;
    const validProfilesList: SimulatorBehavioralProfile[] = ['Questionador Detalhista', 'Ocupado/Impaciente', 'Desconfiado/Silencioso', 'Confuso/Indeciso', 'Comparador', 'Padr√£o'];
    if (!validProfilesList.includes(behavioralProfile)) {
        console.warn(`Perfil comportamental inv√°lido recebido da IA: "${behavioralProfile}". Usando "Padr√£o" como fallback.`);
        behavioralProfile = 'Padr√£o';
    }

    const scenarioId = `sim_procedural_${(parsedFields.LEAD_NAME || 'anon').toLowerCase().replace(/[^a-z0-9]+/gi, '_')}_${Date.now()}`;

    const scenario: Scenario = {
      id: scenarioId,
      title: title,
      context: context,
      initialMessage: parsedFields.INITIAL_MESSAGE_TO_CONSULTANT,
      behavioralProfile: behavioralProfile,
    };
    
    return scenario;

  } catch (error) {
    console.error('Erro ao gerar cen√°rio procedural com Gemini:', error);
    throw error; 
  }
}


export async function transcribeAudioWithGemini(audioBase64: string, mimeType: string = 'audio/webm'): Promise<AudioTranscriptionResponse> {
    if (!API_KEY) return { error: API_KEY_ERROR_MESSAGE };

    try {
        const audioPart: Part = {
            inlineData: {
                mimeType: mimeType,
                data: audioBase64,
            },
        };
        const textPart: Part = {
            text: "Transcreva o seguinte √°udio em portugu√™s brasileiro. Responda APENAS com a transcri√ß√£o do √°udio. Se o √°udio estiver inintelig√≠vel ou vazio, responda com '[√Åudio n√£o compreendido]'.",
        };

        const response: GenerateContentResponse = await ai.models.generateContent({
            model: 'gemini-2.5-flash-preview-04-17',
            contents: { parts: [audioPart, textPart] },
            config: { thinkingConfig: { thinkingBudget: 0 } }
        });

        let transcribedText = response.text.trim();
        const fenceRegex = /^```(\w*)?\s*\n?(.*?)\n?\s*```$/s;
        const match = transcribedText.match(fenceRegex);
        if (match && match[2]) {
          transcribedText = match[2].trim();
        }

        if (!transcribedText || transcribedText.toLowerCase() === '[√°udio n√£o compreendido]') {
            return { text: "" , error: "N√£o foi poss√≠vel transcrever o √°udio ou o √°udio estava inintelig√≠vel." };
        }
        return { text: transcribedText };

    } catch (error) {
        console.error('Erro ao transcrever √°udio com Gemini:', error);
        const errorMessage = (error as Error).message || "Um erro desconhecido ocorreu durante a transcri√ß√£o.";
        if (errorMessage.includes('SERVICE_UNAVAILABLE') || errorMessage.includes('Deadline exceeded')) {
            return { error: "Servi√ßo de transcri√ß√£o indispon√≠vel ou demorou demais. Tente novamente." };
        }
        if (errorMessage.includes('SAFETY')) {
             return { error: "Conte√∫do do √°udio bloqueado por pol√≠ticas de seguran√ßa." };
        }
        return { error: `Erro na transcri√ß√£o: ${errorMessage}` };
    }
}

export async function evaluateObjectionResponse(objectionText: string, userResponseText: string, objectionContext?: string): Promise<string> {
  if (!API_KEY) throw new Error(API_KEY_ERROR_MESSAGE);

  let prompt = GEMINI_OBJECTION_EVALUATOR_PROMPT;
  prompt = prompt.replace("{OBJECTION_TEXT}", objectionText);
  prompt = prompt.replace("{OBJECTION_CONTEXT}", objectionContext || "Nenhum contexto adicional fornecido.");
  prompt = prompt.replace("{USER_RESPONSE}", userResponseText);

  try {
    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-2.5-flash-preview-04-17',
      contents: [{role: 'user', parts: [{text: prompt}]}],
      config: {} 
    });
    return response.text;
  } catch (error) {
    console.error('Erro ao avaliar resposta √† obje√ß√£o com Gemini:', error);
    if ((error as any)?.response?.promptFeedback?.blockReason) {
        return `A avalia√ß√£o da sua resposta foi bloqueada pela IA. Motivo: ${(error as any).response.promptFeedback.blockReason}. Por favor, reformule sua resposta ou a obje√ß√£o.`;
    }
    return `Desculpe, ocorreu um erro ao processar a avalia√ß√£o: ${(error as Error).message}`;
  }
}

export async function generateCollaboratorAnalysis(
  userData: string,
  managerPromptTemplate: string
): Promise<string> {
  if (!API_KEY) throw new Error(API_KEY_ERROR_MESSAGE);

  const finalPrompt = managerPromptTemplate.replace("{USER_DATA_PLACEHOLDER}", userData);

  try {
    const response: GenerateContentResponse = await ai.models.generateContent({
      model: 'gemini-2.5-flash-preview-04-17',
      contents: [{ role: "user", parts: [{text: finalPrompt}] }],
    });
    return response.text;
  } catch (error) {
    console.error('Erro ao gerar an√°lise do colaborador com Gemini:', error);
    if ((error as any)?.response?.promptFeedback?.blockReason) {
        return `A an√°lise foi bloqueada pela IA. Motivo: ${(error as any).response.promptFeedback.blockReason}.`;
    }
    throw new Error(`Falha ao gerar an√°lise cr√≠tica da IA: ${(error as Error).message}`);
  }
}
